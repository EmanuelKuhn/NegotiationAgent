import org.tensorflow.Graph;
import org.tensorflow.Operand;
import org.tensorflow.Session;
import org.tensorflow.Tensor;
import org.tensorflow.ndarray.Shape;
import org.tensorflow.ndarray.buffer.FloatDataBuffer;
import org.tensorflow.op.Ops;
import org.tensorflow.op.core.Assign;
import org.tensorflow.op.core.Constant;
import org.tensorflow.op.core.Placeholder;
import org.tensorflow.op.train.ApplyGradientDescent;
import org.tensorflow.types.TFloat32;

import java.util.List;

import static org.tensorflow.op.core.Placeholder.shape;

public class UtilityModel {

    // Training tuple
    public static class TrainingExample {
        // input
        int[] options;

        // Expected output
        boolean accepted;

        // Used for testing
        float actualValue;

        public TrainingExample(int[] options, boolean accepted) {
            this.options = options;
            this.accepted = accepted;
        }

    }

    Graph graph;
    Ops tf;
    Utility utility;

    List<ApplyGradientDescent<TFloat32>> gradientDescents;
    Placeholder<TFloat32> actuallyAccepted;
    Operand<TFloat32> predicted;

    private final Session session;

    public UtilityModel(int[] issuesOptions) {
        graph = new Graph();

        tf = Ops.create(graph);

        // This creates all the necessary tensorflow Placeholder's and Variable's
        // They can be referenced by e.g. utility.issues[0].issueOneHotVectorPlaceholder for the first issues onehotvector
        utility = new Utility(tf, issuesOptions);


        List<Assign<TFloat32>> assigns = utility.initIssueWeights(tf, 0.5f);
        assigns.add(utility.initWeights(tf, 1.0f));

        predicted = utility.predictUtility(tf);

        // Actually accepted placeholder
        actuallyAccepted = tf.placeholder(TFloat32.DTYPE, shape(Shape.scalar()));

        // A different loss might work better, but this seemed to work a lot better than MSE
        // Loss (should be negatively proportional to the probability that the example was generated by the model)
        Operand<TFloat32> loss = tf.nn.elu(tf.math.square(tf.math.sub(actuallyAccepted, predicted)));
        tf.ensureShape(loss, Shape.scalar());

        Constant<TFloat32> alpha = tf.constant(0.01f);

        gradientDescents = utility.applyGradientDescent(tf, loss, alpha);

        session = new Session(graph);

        // Initialize graph variables
        Session.Runner runner = session.runner();

        for (Assign<TFloat32> assign: assigns) {
            runner.addTarget(assign);
        }

        runner.run();
    }

    // Each int[] represents the choice for an option per issue, e.g. [4, 2] represents choice of option 4 on issue 0 and option 2 on issue 1
    public void train(List<TrainingExample> trainingExamples) {
        for (int i = 0; i < 10; i++) {
            for (TrainingExample example : trainingExamples) {
                float actual = example.accepted ? 1.0f : 0.0f;

                Session.Runner runner = session.runner();

                // Add gradient descent targets
                for (ApplyGradientDescent<TFloat32> gradDescent : this.gradientDescents) {
                    runner.addTarget(gradDescent);
                }

                // Feed in training data
                utility.feed(runner, example.options);
                runner.feed(this.actuallyAccepted, TFloat32.scalarOf(actual));

                // Run with training targets
                runner.run();
            }
        }
    }

    public float predict(int[] options) {

        Session.Runner runner = session.runner();

        utility.feed(runner, options);

        float predictedAcceptedValue = runner.fetch(this.predicted)
                .run().get(0).rawData().asFloats().getFloat(0);

        return predictedAcceptedValue;
    }

    public void printWeights() {

        for(Issue issue: utility.issues) {
            Tensor<?> computedIssueWeights = session.runner().fetch(issue.issueWeights).run().get(0);

            System.out.println("Weight issue" + issue.issueIdx + " is " + computedIssueWeights);

            FloatDataBuffer floats = computedIssueWeights.rawData().asFloats();

            for (int i = 0; i < floats.size(); i++) {
                System.out.println("Weight issue" + issue.issueIdx + " data["+ i +"] " + floats.getFloat(i));
            }
        }

        Tensor<?> computedWeights = session.runner().fetch(utility.weights).run().get(0);
        System.out.println("Weight is " + computedWeights);

        FloatDataBuffer floats = computedWeights.rawData().asFloats();

        for (int i = 0; i < floats.size(); i++) {
            System.out.println("Weight data["+ i +"] " + floats.getFloat(i));
        }

    }

    public static void main(String[] args) {
        UtilityModel model = new UtilityModel(new int[]{2, 3, 5});

        model.train(List.of(
                new TrainingExample(new int[]{0, 2, 0}, true),
                new TrainingExample(new int[]{0, 1, 0}, true),
                new TrainingExample(new int[]{1, 1, 0}, false)));

        System.out.println(model.predict(new int[]{0, 2, 0}));
        System.out.println(model.predict(new int[]{0, 1, 0}));
        System.out.println(model.predict(new int[]{1, 1, 0}));

        System.out.println(model.predict(new int[]{1, 2, 0}));
        System.out.println(model.predict(new int[]{0, 0, 0}));
    }
}
